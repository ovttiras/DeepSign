{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iv99WLkO8zmG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3Omy-vLt-y2v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общее количество изображений: 2640\n",
      "Настоящие подписи (1): 1320\n",
      "Поддельные подписи (0): 1320\n",
      "Процент настоящих подписей: 50.0%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "X = []  # изображения\n",
    "y = []  # метки (0 - подделка, 1 - настоящая подпись)\n",
    "\n",
    "base_path = 'signatures'  # Путь к папке (не ZIP!)\n",
    "\n",
    "for person_folder in os.listdir(base_path):\n",
    "    person_path = os.path.join(base_path, person_folder)\n",
    "\n",
    "    # Пропускаем, если это не папка\n",
    "    if not os.path.isdir(person_path):\n",
    "        continue\n",
    "\n",
    "    for filename in os.listdir(person_path):\n",
    "        file_path = os.path.join(person_path, filename)\n",
    "\n",
    "        # Пропускаем скрытые/неизвестные файлы\n",
    "        if not filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Проверка, что изображение загружено\n",
    "        if img is None:\n",
    "            print(f\"Ошибка загрузки: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        # Обработка изображения\n",
    "        img = cv2.resize(img, (220, 155))  # стандартный размер\n",
    "        _, img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "        X.append(img)\n",
    "\n",
    "        # ИСПРАВЛЕНИЕ: Определение метки на основе папки и имени файла\n",
    "        if person_folder == 'full_org' or 'original' in filename.lower():\n",
    "            y.append(1)  # настоящая подпись\n",
    "        else:\n",
    "            y.append(0)  # поддельная подпись\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Проверим распределение меток\n",
    "print(f\"Общее количество изображений: {len(X)}\")\n",
    "print(f\"Настоящие подписи (1): {np.sum(y == 1)}\")\n",
    "print(f\"Поддельные подписи (0): {np.sum(y == 0)}\")\n",
    "print(f\"Процент настоящих подписей: {np.mean(y == 1)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "haHVkffpFmI_"
   },
   "outputs": [],
   "source": [
    "# Нормализация пикселей (0-1)\n",
    "X = X / 255.0\n",
    "\n",
    "# Добавляем канал (для чёрно-белых изображений)\n",
    "X = X.reshape(-1, 155, 220, 1)\n",
    "\n",
    "# Разделение на обучение и тест\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "480nvqGDF1n9",
    "outputId": "4144fb25-5fe3-475a-d121-3f9daec7b8aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(155, 220, 1)),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # 1 выходной нейрон для задачи бинарной классификации\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUGrL525F_EN",
    "outputId": "21b5187a-6213-4ebf-ee0e-2b015a9e923e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 413ms/step - accuracy: 0.6946 - loss: 0.5849 - val_accuracy: 0.7652 - val_loss: 0.5082\n",
      "Epoch 2/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 351ms/step - accuracy: 0.8338 - loss: 0.3775 - val_accuracy: 0.7860 - val_loss: 0.4651\n",
      "Epoch 3/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 353ms/step - accuracy: 0.9209 - loss: 0.2002 - val_accuracy: 0.7992 - val_loss: 0.4873\n",
      "Epoch 4/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 349ms/step - accuracy: 0.9692 - loss: 0.0971 - val_accuracy: 0.8163 - val_loss: 0.5645\n",
      "Epoch 5/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 351ms/step - accuracy: 0.9905 - loss: 0.0463 - val_accuracy: 0.8277 - val_loss: 0.6891\n",
      "Epoch 6/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 350ms/step - accuracy: 0.9867 - loss: 0.0417 - val_accuracy: 0.8220 - val_loss: 0.6272\n",
      "Epoch 7/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 353ms/step - accuracy: 0.9929 - loss: 0.0247 - val_accuracy: 0.8182 - val_loss: 0.7206\n",
      "Epoch 8/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 376ms/step - accuracy: 0.9938 - loss: 0.0177 - val_accuracy: 0.8163 - val_loss: 0.7807\n",
      "Epoch 9/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 367ms/step - accuracy: 0.9915 - loss: 0.0282 - val_accuracy: 0.8144 - val_loss: 0.7575\n",
      "Epoch 10/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 361ms/step - accuracy: 0.9943 - loss: 0.0219 - val_accuracy: 0.7917 - val_loss: 0.7377\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gySrJiZUGEXO",
    "outputId": "c6b53ca6-3491-4caf-e231-0e93953e9d6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7917 - loss: 0.7377\n",
      "Test accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cv450VQlOBc-"
   },
   "outputs": [],
   "source": [
    "def predict_signature(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (220, 155))\n",
    "    _, img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    img = img / 255.0\n",
    "    img = img.reshape(1, 155, 220, 1)\n",
    "\n",
    "    prediction = model.predict(img)\n",
    "\n",
    "    if prediction >= 0.5:\n",
    "        print(f\"Prediction: Genuine Signature ({prediction[0][0]:.2f})\")\n",
    "    else:\n",
    "        print(f\"Prediction: Forged Signature ({prediction[0][0]:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YkQEGXl3Omrl",
    "outputId": "9c8a2040-dcaf-4bba-dbb6-1e3afcd53949"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Сохраняем модель\n",
    "model.save('signature_verification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1kH-_IwO6T-",
    "outputId": "96f7247c-1b6e-48de-c819-e6224d75e8f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "Prediction: Genuine Signature (0.92)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Загружаем сохранённую модель\n",
    "model = load_model('signature_verification_model.h5')\n",
    "\n",
    "# Теперь модель готова к использованию!\n",
    "predict_signature('example/norm_1_1.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Загружаем сохранённую модель\n",
    "model = load_model('signature_verification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ovtti\\AppData\\Local\\Temp\\tmpwq1zsv3w\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ovtti\\AppData\\Local\\Temp\\tmpwq1zsv3w\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\ovtti\\AppData\\Local\\Temp\\tmpwq1zsv3w'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 155, 220, 1), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2378516184912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2378492003152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2378492007184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2378492007568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2378492007952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2378492003920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2378492006416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2378492006608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Загружаем модель из .h5\n",
    "model = tf.keras.models.load_model(\"signature_verification_model.h5\")\n",
    "\n",
    "# Конвертация в .tflite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# (опционально) включаем квантизацию\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Сохраняем\n",
    "tflite_model = converter.convert()\n",
    "with open(\"model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pdG_WfOqPgEO"
   },
   "outputs": [],
   "source": [
    "# Загружаем сохранённую модель\n",
    "model = load_model('signature_verification_model.h5')\n",
    "\n",
    "# Переобучаем модель на новых данных\n",
    "history = model.fit(\n",
    "    X_new,  # новые изображения\n",
    "    y_new,  # новые метки\n",
    "    epochs=5,  # количество новых эпох\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test)  # для проверки на старых данных\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ПЕРЕОБУЧЕНИЕ МОДЕЛИ С ИСПРАВЛЕННЫМИ ДАННЫМИ\n",
    "print(\"Переобучение модели с исправленными метками...\")\n",
    "\n",
    "# Создаем новую модель\n",
    "model_fixed = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(155, 220, 1)),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # 1 выходной нейрон для задачи бинарной классификации\n",
    "])\n",
    "\n",
    "model_fixed.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Обучаем модель с исправленными данными\n",
    "history_fixed = model_fixed.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Оцениваем модель\n",
    "test_loss, test_acc = model_fixed.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy с исправленными данными: {test_acc:.2f}\")\n",
    "\n",
    "# Сохраняем исправленную модель\n",
    "model_fixed.save('signature_verification_model_fixed.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ТЕСТИРОВАНИЕ ИСПРАВЛЕННОЙ МОДЕЛИ\n",
    "def predict_signature_fixed(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (220, 155))\n",
    "    _, img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    img = img / 255.0\n",
    "    img = img.reshape(1, 155, 220, 1)\n",
    "\n",
    "    prediction = model_fixed.predict(img)\n",
    "\n",
    "    if prediction >= 0.5:\n",
    "        print(f\"Prediction: Genuine Signature ({prediction[0][0]:.2f})\")\n",
    "    else:\n",
    "        print(f\"Prediction: Forged Signature ({prediction[0][0]:.2f})\")\n",
    "\n",
    "# Тестируем на примерах\n",
    "print(\"Тестирование исправленной модели:\")\n",
    "print(\"\\n1. Тест на настоящей подписи (original_1_1.png):\")\n",
    "predict_signature_fixed('example/original_1_1.png')\n",
    "\n",
    "print(\"\\n2. Тест на поддельной подписи (forgeries_1_1.png):\")\n",
    "predict_signature_fixed('example/forgeries_1_1.png')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
